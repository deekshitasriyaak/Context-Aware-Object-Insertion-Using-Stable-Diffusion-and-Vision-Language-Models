# Context-Aware-Object-Insertion-Using-Stable-Diffusion-and-Vision-Language-Models

This project introduces an innovative method for seamlessly inserting an object from one image into a scene from another image while considering perspective, size, and contextual relevance. By integrating a pre-trained Stable Diffusion Inpainting pipeline with the Vision-Language Model (VLM) LLaVa, our approach ensures high-quality results. The workflow begins with two input images and a user-defined mask. LLaVa extracts detailed features and generates an accurate textual description of the object. This description, along with the scene image and mask, is then processed by the Stable Diffusion pipeline. The result is a highly realistic and contextually coherent inpainting, suitable for applications in augmented reality, digital art, interior design, and content creation.

Methodology

Our approach combines vision-language modeling and diffusion-based image generation for contextually aware object insertion in images. It consists of three main components:

A. Prompt Generation with LLaVa

We use the LLaVa-1.5-7b model to understand and describe visual content. The object image is converted to RGB format, and a predefined prompt template guides the model. The LLaVa model generates a concise textual description of the object with specific insertion instructions.

B. Mask Creation

A binary mask is automatically generated by the program to define the insertion area. The mask, hard-coded into the program, is validated and preprocessed to ensure compatibility with the inpainting pipeline.

C. Image Inpainting with Stable Diffusion

We use the Stable Diffusion Inpainting pipeline, loading the StableDiffusionInpaintPipeline from the runwayml/stable-diffusion-inpainting model. The target image, LLaVa-generated prompt, and validated mask are processed to generate the final image with the object seamlessly inserted.

D. Implementation Details

The implementation uses libraries like transformers, diffusers, torch, and PIL on a CUDA-compatible GPU. Key optimizations include efficient model loading and precision configurations. This method ensures high fidelity and contextual accuracy in the resulting images by leveraging LLaVa's descriptive capabilities and Stable Diffusion's generative power.



Architecture:

<img width="662" alt="Screenshot 2024-07-15 at 10 08 05â€¯AM" src="https://github.com/user-attachments/assets/55cb2c9b-5e06-450d-9298-3fae1727e6dd">
